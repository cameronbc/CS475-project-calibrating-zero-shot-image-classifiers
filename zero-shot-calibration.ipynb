{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cameronbc/CS475-project-calibrating-zero-shot-image-classifiers/blob/main/zero-shot-calibration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFDDTVIfrR1X"
      },
      "source": [
        "# Experiments in Calibrating Zero-Shot Image Classifiers\n",
        "\n",
        "This notebooks contains code for experimenting with different calibration methods for binary classifiers, applied to the use case of zero-shot image classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfhsUvCmrnA6"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtJDwDynjCz9"
      },
      "outputs": [],
      "source": [
        "! sudo apt install dvipng texlive-latex-extra texlive-fonts-recommended texlive-fonts-extra cm-super\n",
        "! pip install --upgrade datasets open_clip_torch relplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96pbjsP1rsTD"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFTaNWWv05WA"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pathlib\n",
        "\n",
        "import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import open_clip\n",
        "import pandas as pd\n",
        "import PIL.Image\n",
        "import PIL.PngImagePlugin\n",
        "import relplot\n",
        "import scipy.special\n",
        "import seaborn as sns\n",
        "import sklearn.calibration\n",
        "import sklearn.isotonic\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import torch\n",
        "import tqdm.auto as tqdm\n",
        "\n",
        "# fix image loading errors for some large files\n",
        "PIL.PngImagePlugin.MAX_TEXT_CHUNK = 100 * (1024**2)\n",
        "\n",
        "# have relplot make pretty LaTeX axis labels\n",
        "relplot.config.use_tex_fonts = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8pgo3-6rzoB"
      },
      "source": [
        "## Fetch Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwyu2pvIxDz2"
      },
      "outputs": [],
      "source": [
        "DATASET_URLS = {\n",
        "    # Aerial Image Dataset: https://captain-whu.github.io/AID/\n",
        "    \"aid\": \"https://drive.google.com/uc?id=1CTdCFoo88_ygMb2PNGnK3QTi8xk_naoA\",\n",
        "    # MIT Places 365: http://places2.csail.mit.edu/\n",
        "    \"places365\": \"https://drive.google.com/uc?id=1w-0LncVMfBsdtqX7jT-jCTdAnLBZuFtU\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUKd0snOr_qn"
      },
      "outputs": [],
      "source": [
        "for dataset_name, dataset_gdrive_url in DATASET_URLS.items():\n",
        "    ! gdown {dataset_gdrive_url}\n",
        "    ! mkdir {dataset_name}\n",
        "    ! unzip /content/{dataset_name}.zip -d {dataset_name}\n",
        "    ! rm /content/{dataset_name}.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iorWHMMmsAcu"
      },
      "source": [
        "## Implement Zero-Shot Classifier and Calibrators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jfxqtZY1iNk"
      },
      "outputs": [],
      "source": [
        "class ZeroShotClassifier:\n",
        "    \"\"\"Wrapper for loading and running zero-shot image classifiers.\"\"\"\n",
        "\n",
        "    TEMPLATES = [\n",
        "        \"itap of a {}.\",\n",
        "        \"a bad photo of the {}.\",\n",
        "        \"a origami {}.\",\n",
        "        \"a photo of the large {}.\",\n",
        "        \"a {} in a video game.\",\n",
        "        \"art of the {}.\",\n",
        "        \"a photo of the small {}.\",\n",
        "    ]\n",
        "\n",
        "    def __init__(self, model_name, pretrained_source, device):\n",
        "        \"\"\"Create a new instance of the zero-shot classifier.\"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.pretrained_source = pretrained_source\n",
        "        self.device = device\n",
        "        self.model, _, self.preprocess = open_clip.create_model_and_transforms(\n",
        "            self.model_name,\n",
        "            pretrained=self.pretrained_source,\n",
        "        )\n",
        "        self.model.eval().to(device)\n",
        "        self.tokenizer = open_clip.get_tokenizer(self.model_name)\n",
        "        self.text = None\n",
        "        self.text_features = None\n",
        "\n",
        "    def set_text(self, text):\n",
        "        \"\"\"Set the text prompt for the classifier.\"\"\"\n",
        "        self.text = text\n",
        "        tokens = self.tokenizer(\n",
        "            [t.format(self.text) for t in ZeroShotClassifier.TEMPLATES]\n",
        "        )\n",
        "        with torch.no_grad(), torch.amp.autocast(\"cuda\"):\n",
        "            text_features = self.model.encode_text(tokens.to(self.device))\n",
        "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "            text_features = text_features.mean(dim=0)\n",
        "            text_features /= text_features.norm()\n",
        "        self.text_features = text_features.to(\"cpu\").numpy()\n",
        "\n",
        "    def get_image_features(self, image: PIL.Image.Image):\n",
        "        \"\"\"Get CLIP features for a single image.\"\"\"\n",
        "        input_features = self.preprocess(image).unsqueeze(0)\n",
        "        with torch.no_grad(), torch.amp.autocast(\"cuda\"):\n",
        "            image_features = self.model.encode_image(input_features.to(self.device))\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        return image_features.to(\"cpu\").numpy()\n",
        "\n",
        "    def get_image_features_batch(self, images):\n",
        "        \"\"\"Get CLIP features for a batch of images.\"\"\"\n",
        "        input_features = torch.stack([self.preprocess(im) for im in images])\n",
        "        with torch.no_grad(), torch.amp.autocast(\"cuda\"):\n",
        "            image_features = self.model.encode_image(input_features.to(self.device))\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        return image_features.cpu().numpy()\n",
        "\n",
        "    def score_image(self, image: PIL.Image.Image, with_features: bool = False):\n",
        "        \"\"\"Score an image based on the text prompt.\"\"\"\n",
        "        image_features = self.get_image_features(image)\n",
        "        score = (image_features @ self.text_features).item()\n",
        "        results = {\"score\": score.astype(np.float32)}\n",
        "        if with_features:\n",
        "            results[\"features\"] = image_features\n",
        "        return results\n",
        "\n",
        "    def score_image_batch(self, images, with_features=False):\n",
        "        \"\"\"Score a batch of images based on the text prompt.\"\"\"\n",
        "        image_features = self.get_image_features_batch(images)\n",
        "        scores = image_features @ self.text_features\n",
        "        results = {\"score\": scores.astype(np.float32)}\n",
        "        if with_features:\n",
        "            results[\"features\"] = image_features\n",
        "        return results\n",
        "\n",
        "    def score_features(self, image_features: np.ndarray):\n",
        "        \"\"\"Score image features based on the text prompt.\"\"\"\n",
        "        score = (image_features @ self.text_features).item()\n",
        "        return score.astype(np.float32)\n",
        "\n",
        "    def score_features_batch(self, image_features: np.ndarray):\n",
        "        \"\"\"Score a batch of image features based on the text prompt.\"\"\"\n",
        "        scores = image_features @ self.text_features\n",
        "        return scores.astype(np.float32)\n",
        "\n",
        "\n",
        "class BaseCalibrator:\n",
        "    \"\"\"Base class for score calibration methods.\"\"\"\n",
        "\n",
        "    def fit(self, scores: np.ndarray, labels: np.ndarray):\n",
        "        \"\"\"Train the calibrator.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Calibrate scores into probabilities.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class IsotonicCalibrator(BaseCalibrator):\n",
        "    \"\"\"Calibrate scores using isotonic regression.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Create a new instance of the isotonic calibrator.\"\"\"\n",
        "        self.calibrator = sklearn.isotonic.IsotonicRegression(out_of_bounds=\"clip\")\n",
        "\n",
        "    def fit(self, scores: np.ndarray, labels: np.ndarray) -> \"IsotonicCalibrator\":\n",
        "        \"\"\"Fit the isotonic calibrator.\"\"\"\n",
        "        self.calibrator.fit(scores, labels)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply isotonic calibration to scores.\"\"\"\n",
        "        return self.calibrator.predict(scores)\n",
        "\n",
        "\n",
        "class SigmoidCalibrator(BaseCalibrator):\n",
        "    \"\"\"Calibrates scores using sigmoid/Platt scaling.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Create a new instance of the sigmoid calibrator.\"\"\"\n",
        "        self.calibrator = sklearn.calibration._SigmoidCalibration()  # brittle\n",
        "\n",
        "    def fit(self, scores: np.ndarray, labels: np.ndarray) -> \"SigmoidCalibrator\":\n",
        "        \"\"\"Fit the sigmoid calibrator\"\"\"\n",
        "        self.calibrator.fit(scores, labels)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply sigmoid calibration to scores.\"\"\"\n",
        "        return self.calibrator.predict(scores)\n",
        "\n",
        "\n",
        "class SigLIPCalibrator(BaseCalibrator):\n",
        "    \"\"\"Calibrates scores using sigmoid/Platt scaling.\"\"\"\n",
        "\n",
        "    def __init__(self, zsc: ZeroShotClassifier, target_prior=None) -> None:\n",
        "        \"\"\"Create a new instance of the SigLIP sigmoid-style calibrator.\"\"\"\n",
        "        if \"siglip\" not in zsc.model_name.lower():\n",
        "            raise ValueError(\"Zero-shot classifier not a sigLIP instance\")\n",
        "        with torch.no_grad():\n",
        "            self.scale = zsc.model.logit_scale.exp().cpu().numpy()  # AKA slope\n",
        "            self.shift = zsc.model.logit_bias.cpu().numpy()  # AKA intercept\n",
        "        self.target_prior = target_prior\n",
        "        if self.target_prior is not None:\n",
        "            self.shift = np.log(self.target_prior / (1 - self.target_prior))\n",
        "\n",
        "    def fit(self, scores: np.ndarray, labels: np.ndarray) -> \"SigLIPCalibrator\":\n",
        "        \"\"\"Fit the sigLIP calibrator (does nothing, comes trained from sigLIP)\"\"\"\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply sigmoid calibration to scores.\"\"\"\n",
        "        return scipy.special.expit(self.scale * scores + self.shift)\n",
        "\n",
        "\n",
        "class SimilarityBinningAveragingCalibrator(BaseCalibrator):\n",
        "    \"\"\"Calibrate scores using Similarity-Binning Averaging calibration.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        k: int = 10,\n",
        "        alpha: float = 0.95,\n",
        "        inner_calibration_class: BaseCalibrator = SigmoidCalibrator,\n",
        "    ) -> None:\n",
        "        \"\"\"Create a new instance of the SBA calibrator.\n",
        "\n",
        "        k: number of nearest neighbors in the bin to average over\n",
        "        alpha: weighting factor between CLIP features and class probs for similarity\n",
        "        inner_calibration_class: method for getting calibrated scores from calibration data\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "        self.alpha = alpha\n",
        "        self.inner_calibrator = inner_calibration_class()\n",
        "        self._train_features = None\n",
        "        self._train_probs = None\n",
        "\n",
        "    def fit(\n",
        "        self, scores: np.ndarray, labels: np.ndarray, features: np.ndarray\n",
        "    ) -> \"SimilarityBinningAveragingCalibrator\":\n",
        "        \"\"\"Fit the SBA calibrator\"\"\"\n",
        "        self.inner_calibrator.fit(scores, labels)\n",
        "        self._train_features = features\n",
        "        self._train_probs = self.inner_calibrator.predict_proba(scores)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray, features: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply SBA calibration to scores.\"\"\"\n",
        "        feature_similarities = features @ self._train_features.T\n",
        "        fs_max = feature_similarities.max()\n",
        "        fs_min = feature_similarities.min()\n",
        "        feature_similarities = (feature_similarities - fs_min) / fs_max\n",
        "        probs = self.inner_calibrator.predict_proba(scores)\n",
        "        probs_similarities = 1 - np.abs(probs[:, np.newaxis] - self._train_probs)\n",
        "        similarities = (\n",
        "            self.alpha * feature_similarities + (1 - self.alpha) * probs_similarities\n",
        "        )\n",
        "        top_k_indices = np.argsort(-similarities, axis=1)[:, : self.k]\n",
        "        top_k_probs = self._train_probs[top_k_indices]\n",
        "        return top_k_probs.mean(axis=1)\n",
        "\n",
        "\n",
        "def build_features_dataset(\n",
        "    zero_shot_classifier: ZeroShotClassifier,\n",
        "    image_dataset: datasets.Dataset,\n",
        "    batch_size: int = 32,\n",
        "    keep_in_memory: bool = False,\n",
        "):\n",
        "    \"\"\"Compute and add extracted CLIP features as a column in an image dataset.\"\"\"\n",
        "    features_dataset = image_dataset.map(\n",
        "        lambda images: dict(\n",
        "            features=zero_shot_classifier.get_image_features_batch(images)\n",
        "        ),\n",
        "        input_columns=[\"image\"],\n",
        "        batched=True,\n",
        "        batch_size=batch_size,\n",
        "        keep_in_memory=keep_in_memory,\n",
        "        desc=\"Extracting features\",\n",
        "    )\n",
        "    return features_dataset.remove_columns(\"image\")\n",
        "\n",
        "\n",
        "def build_scores_dataset(\n",
        "    zero_shot_classifier: ZeroShotClassifier,\n",
        "    features_dataset: pd.DataFrame,\n",
        "    batch_size: int = 1024,\n",
        "    keep_in_memory: bool = False,\n",
        "):\n",
        "    \"\"\"Compute and add zero-shot scores as a column in a features dataset.\"\"\"\n",
        "    features = np.stack(features_dataset[\"features\"].values)\n",
        "    scores = zero_shot_classifier.score_features_batch(features)\n",
        "    scores_dataset = features_dataset.copy()\n",
        "    scores_dataset[\"score\"] = scores\n",
        "    return scores_dataset\n",
        "\n",
        "\n",
        "def places365_clean_label(label: str):\n",
        "    \"\"\"Clean up Places365 labels for use in zero-shot prompting.\"\"\"\n",
        "    if \"-\" in label:\n",
        "        noun, adj = label.rsplit(\"-\", 1)\n",
        "        label = f\"{adj} {noun}\"\n",
        "    return label.replace(\"_\", \" \")\n",
        "\n",
        "\n",
        "def create_binary_dataset(\n",
        "    multiclass_dataset: pd.DataFrame,\n",
        "    target_class_id: int,\n",
        "    target_prior: float = 0.5,\n",
        "    keep_in_memory: bool = False,\n",
        "):\n",
        "    \"\"\"Create a binary dataset from a multiclass dataset.\n",
        "\n",
        "    The binary dataset will have a target class and a non-target class, with the\n",
        "    non-target class sampled at a specified ratio to the target class.\n",
        "    \"\"\"\n",
        "    num_target_samples = sum(\n",
        "        label == target_class_id for label in multiclass_dataset[\"label\"]\n",
        "    )\n",
        "    num_non_target_samples = len(multiclass_dataset) - num_target_samples\n",
        "    non_target_odds = (1.0 - target_prior) / target_prior\n",
        "    num_non_target_keep = non_target_odds * num_target_samples\n",
        "    non_target_keep_prob = num_non_target_keep / num_non_target_samples\n",
        "\n",
        "    keep = []\n",
        "    for i, label in enumerate(multiclass_dataset[\"label\"]):\n",
        "        if label == target_class_id:\n",
        "            keep.append(i)\n",
        "        else:\n",
        "            if np.random.random() < non_target_keep_prob:\n",
        "                keep.append(i)\n",
        "    binary_dataset = multiclass_dataset.filter(keep, axis=0)\n",
        "    binary_dataset[\"label\"] = binary_dataset[\"label\"].apply(\n",
        "        lambda label: int(label == target_class_id)\n",
        "    )\n",
        "    binary_dataset.reset_index(drop=True, inplace=True)\n",
        "    return binary_dataset\n",
        "\n",
        "\n",
        "def plot_score_distributions(score_dataset: datasets.Dataset, title: str):\n",
        "    \"\"\"Plot histograms of target and non-target scores.\"\"\"\n",
        "    target_scores = score_dataset[\"score\"][score_dataset[\"label\"] == 1]\n",
        "    non_target_scores = score_dataset[\"score\"][score_dataset[\"label\"] == 0]\n",
        "\n",
        "    sns.histplot(\n",
        "        target_scores,\n",
        "        stat=\"density\",\n",
        "        alpha=0.6,\n",
        "        color=\"#2ecc71\",\n",
        "        label=\"Target\",\n",
        "        bins=30,\n",
        "    )\n",
        "    sns.histplot(\n",
        "        non_target_scores,\n",
        "        stat=\"density\",\n",
        "        alpha=0.6,\n",
        "        color=\"#e74c3c\",\n",
        "        label=\"Non-Target\",\n",
        "        bins=30,\n",
        "    )\n",
        "\n",
        "    plt.axvline(\n",
        "        target_scores.mean(),\n",
        "        color=\"#27ae60\",\n",
        "        linestyle=\"--\",\n",
        "        alpha=0.8,\n",
        "        label=\"Target Mean\",\n",
        "    )\n",
        "    plt.axvline(\n",
        "        non_target_scores.mean(),\n",
        "        color=\"#c0392b\",\n",
        "        linestyle=\"--\",\n",
        "        alpha=0.8,\n",
        "        label=\"Non-Target Mean\",\n",
        "    )\n",
        "\n",
        "    plt.xlabel(\"Model Score\")\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFPPG5RuvC8m"
      },
      "source": [
        "## Create Zero-Shot Classifier and Extract Image Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmpALZI_oP-R"
      },
      "outputs": [],
      "source": [
        "! mkdir -p /content/results\n",
        "! rm -rf /content/results/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDagCaOGqDe8"
      },
      "outputs": [],
      "source": [
        "print(\"Creating zero-shot classifier\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_name, provider = \"ViT-B-32-quickgelu\", \"openai\"\n",
        "#model_name, provider = \"ViT-B-16-SigLIP\", \"webli\"\n",
        "#model_name, provider = \"ViT-B-32\", \"datacomp_m_s128m_b4k\"\n",
        "#model_name, provider = \"RN50-quickgelu\", \"yfcc15m\"\n",
        "zsc = ZeroShotClassifier(model_name, provider, device)\n",
        "\n",
        "print(\"Extracting CLIP features for AID dataset\")\n",
        "aid_dataset = datasets.load_from_disk(\"/content/aid\")\n",
        "aid_dataset = build_features_dataset(zsc, aid_dataset)\n",
        "aid_dataset.set_format(type=\"numpy\")\n",
        "\n",
        "print(\"Extracting CLIP features for Places365 dataset (takes several minutes)\")\n",
        "places_dataset = datasets.load_from_disk(\"/content/places365\")\n",
        "places_dataset = build_features_dataset(zsc, places_dataset)\n",
        "places_dataset.set_format(type=\"numpy\")\n",
        "\n",
        "# class names from AID and Places365 already mapped to match during data prep\n",
        "class_names = places_dataset.features[\"label\"].names\n",
        "class_ids = {c: places_dataset.features[\"label\"].str2int(c) for c in class_names}\n",
        "\n",
        "# use pandas dataframes instead of HF datasets since images no longer needed\n",
        "aid_dataset = pd.DataFrame(aid_dataset)\n",
        "places_dataset = pd.DataFrame(places_dataset)\n",
        "model_slug = f\"{model_name}--{provider}\"\n",
        "results_dir = pathlib.Path(\"/content/results\") / model_slug\n",
        "results_dir.mkdir(exist_ok=True, parents=True)\n",
        "plots_dir = results_dir / \"plots\"\n",
        "plots_dir.mkdir(exist_ok=True, parents=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsuCpFKGkNuw"
      },
      "source": [
        "## Run Zero-Shot Classification and In-Class Calibration and Collect Metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_prior = 1.0 / 3.0\n",
        "calibration_methods = [\"sigmoid\", \"isotonic\", \"SBA\"]\n",
        "if \"siglip\" in zsc.model_name.lower():\n",
        "    calibration_methods.append(\"siglip\")\n",
        "    siglip_calibrator = SigLIPCalibrator(zsc, target_prior=target_prior)\n",
        "in_domain_results = []\n",
        "ood_results = []\n",
        "calibrators = {}\n",
        "in_domain_calibration_test_sets = {}\n",
        "show_plots = False"
      ],
      "metadata": {
        "id": "5MBPOmJF1iRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR8oppgmMcy-"
      },
      "outputs": [],
      "source": [
        "for target_class_name in tqdm.tqdm(class_names):\n",
        "    target_class_id = class_ids[target_class_name]\n",
        "    target_class_name_clean = places365_clean_label(target_class_name)\n",
        "    eval_slug = f\"eval--{target_class_id:>02}--{target_class_name}--inclass\"\n",
        "    print(f\"Processing {eval_slug}\")\n",
        "    zsc.set_text(target_class_name_clean)\n",
        "\n",
        "    # make one-vs-rest version of dataset\n",
        "    # note, we filter out some non-targets to make the dataset more balanced\n",
        "    calibration_dataset = create_binary_dataset(places_dataset, target_class_id, target_prior)\n",
        "    calibration_dataset = build_scores_dataset(zsc, calibration_dataset)\n",
        "    cal_train, cal_test = sklearn.model_selection.train_test_split(\n",
        "        calibration_dataset, test_size=0.5, random_state=42\n",
        "    )\n",
        "    plot_score_distributions(\n",
        "        cal_test,\n",
        "        f\"In-domain Score Distribution for {target_class_name_clean.title()}\",\n",
        "    )\n",
        "    plt.savefig(plots_dir / f\"{eval_slug}--indomain--scores.png\", bbox_inches=\"tight\")\n",
        "    plt.show() if show_plots else plt.close()\n",
        "\n",
        "    # use AID as the out-of-domain test set\n",
        "    calibration_dataset_ood = create_binary_dataset(aid_dataset, target_class_id, target_prior)\n",
        "    cal_test_ood = build_scores_dataset(zsc, calibration_dataset_ood)\n",
        "    plot_score_distributions(\n",
        "        cal_test_ood,\n",
        "        f\"Out-of-domain Score Distribution for {target_class_name_clean.title()}\",\n",
        "    )\n",
        "    plt.savefig(plots_dir / f\"{eval_slug}--ood-scores.png\", bbox_inches=\"tight\")\n",
        "    plt.show() if show_plots else plt.close()\n",
        "\n",
        "    # cache calibration test partition to test in-domain calibration transfer later\n",
        "    in_domain_calibration_test_sets[target_class_name] = cal_test.drop(\"features\", axis=1)\n",
        "\n",
        "    for calibration_method in calibration_methods:\n",
        "        calibrator_args = [cal_train[\"score\"], cal_train[\"label\"]]\n",
        "        predict_proba_args = [cal_test[\"score\"]]\n",
        "        ood_predict_proba_args = [cal_test_ood[\"score\"]]\n",
        "\n",
        "        if calibration_method == \"sigmoid\":\n",
        "            calibrator = SigmoidCalibrator()\n",
        "        elif calibration_method == \"isotonic\":\n",
        "            calibrator = IsotonicCalibrator()\n",
        "        elif calibration_method == \"siglip\":\n",
        "            calibrator = siglip_calibrator\n",
        "        elif calibration_method == \"SBA\":\n",
        "            calibrator = SimilarityBinningAveragingCalibrator()\n",
        "            calibrator_args.append(np.stack(cal_train[\"features\"].values))\n",
        "            predict_proba_args.append(np.stack(cal_test[\"features\"].values))\n",
        "            ood_predict_proba_args.append(np.stack(cal_test_ood[\"features\"].values))\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown calibration method {calibration_method}\")\n",
        "\n",
        "        calibrator.fit(*calibrator_args)\n",
        "        labels = cal_test[\"label\"]\n",
        "        probs = calibrator.predict_proba(*predict_proba_args)\n",
        "        preds = probs >= 0.5\n",
        "        ood_labels = cal_test_ood[\"label\"]\n",
        "        ood_probs = calibrator.predict_proba(*ood_predict_proba_args)\n",
        "        ood_preds = ood_probs >= 0.5\n",
        "\n",
        "        cal_slug = f\"places365--{target_class_id:>02}--{target_class_name}--{calibration_method}\"\n",
        "        if calibration_method != \"SBA\":\n",
        "            calibrators[cal_slug] = calibrator\n",
        "\n",
        "        results_metadata = {\n",
        "            \"model_name\": model_name,\n",
        "            \"provider\": provider,\n",
        "            \"calibration_method\": calibration_method,\n",
        "            \"train_class_id\": target_class_id,\n",
        "            \"train_class_name\": target_class_name,\n",
        "            \"train_class_name_clean\": target_class_name_clean,\n",
        "            \"test_class_id\": target_class_id,\n",
        "            \"test_class_name\": target_class_name,\n",
        "            \"test_class_name_clean\": target_class_name_clean,\n",
        "        }\n",
        "\n",
        "        results_slug = f\"{eval_slug}--indomain--{calibration_method}\"\n",
        "        print(f\"Computing plots and metrics for {results_slug}\")\n",
        "        results = {\n",
        "            # classifier/calibrator metadata\n",
        "            \"test_class_domain\": \"indomain\",\n",
        "            \"slug\": results_slug,\n",
        "            # in-domain classifier metrics\n",
        "            \"accuracy\": sklearn.metrics.accuracy_score(labels, preds),\n",
        "            \"precision\": sklearn.metrics.precision_score(labels, preds),\n",
        "            \"recall\": sklearn.metrics.recall_score(labels, preds),\n",
        "            \"f1\": sklearn.metrics.f1_score(labels, preds),\n",
        "            # in-domain calibration metrics\n",
        "            \"brier_score\": sklearn.metrics.brier_score_loss(labels, probs),\n",
        "            \"sm_ece\": relplot.smECE(probs, labels),\n",
        "            \"binned_ece\": relplot.metrics.binnedECE(probs, labels, nbins=15),\n",
        "        }\n",
        "        in_domain_results.append({**results_metadata, **results})\n",
        "\n",
        "        sklearn.metrics.ConfusionMatrixDisplay.from_predictions(labels, preds)\n",
        "        plt.savefig(plots_dir / f\"{results_slug}-cm.png\", bbox_inches=\"tight\")\n",
        "        plt.show() if show_plots else plt.close()\n",
        "        relplot.rel_diagram(probs, labels)\n",
        "        plt.savefig(plots_dir / f\"{results_slug}-relplot.png\", bbox_inches=\"tight\")\n",
        "        plt.show() if show_plots else plt.close()\n",
        "        relplot.rel_diagram_binned(probs, labels)\n",
        "        plt.savefig(plots_dir / f\"{results_slug}-relplot-binned.png\", bbox_inches=\"tight\")\n",
        "        plt.show() if show_plots else plt.close()\n",
        "\n",
        "        results_slug = f\"{eval_slug}--ood--{calibration_method}\"\n",
        "        print(f\"Computing plots and metrics for {results_slug}\")\n",
        "        results = {\n",
        "            \"test_class_domain\": \"ood\",\n",
        "            \"slug\": results_slug,\n",
        "            # out-of-domain classifier metrics\n",
        "            \"accuracy\": sklearn.metrics.accuracy_score(ood_labels, ood_preds),\n",
        "            \"precision\": sklearn.metrics.precision_score(ood_labels, ood_preds),\n",
        "            \"recall\": sklearn.metrics.recall_score(ood_labels, ood_preds),\n",
        "            \"f1\": sklearn.metrics.f1_score(ood_labels, ood_preds),\n",
        "            # out-of-domain calibration metrics\n",
        "            \"brier_score\": sklearn.metrics.brier_score_loss(ood_labels, ood_probs),\n",
        "            \"sm_ece\": relplot.smECE(ood_probs, ood_labels),\n",
        "            \"binned_ece\": relplot.metrics.binnedECE(ood_probs, ood_labels, nbins=15),\n",
        "        }\n",
        "        ood_results.append({**results_metadata, **results})\n",
        "\n",
        "        sklearn.metrics.ConfusionMatrixDisplay.from_predictions(ood_labels, ood_preds)\n",
        "        plt.savefig(plots_dir / f\"{results_slug}-cm.png\", bbox_inches=\"tight\")\n",
        "        plt.show() if show_plots else plt.close()\n",
        "        relplot.rel_diagram(ood_probs, ood_labels)\n",
        "        plt.savefig(plots_dir / f\"{results_slug}-relplot.png\", bbox_inches=\"tight\")\n",
        "        plt.show() if show_plots else plt.close()\n",
        "        relplot.rel_diagram_binned(ood_probs, ood_labels)\n",
        "        plt.savefig(plots_dir / f\"{results_slug}-relplot-binned.png\", bbox_inches=\"tight\")\n",
        "        plt.show() if show_plots else plt.close()\n",
        "\n",
        "in_domain_df = pd.DataFrame(in_domain_results)\n",
        "save_path = results_dir / f\"metrics--indomain.csv\"\n",
        "in_domain_df.to_csv(save_path)\n",
        "print(f\"wrote in-domain metrics to {save_path}\")\n",
        "\n",
        "ood_df = pd.DataFrame(ood_results)\n",
        "save_path = results_dir / f\"metrics--ood.csv\"\n",
        "ood_df.to_csv(save_path)\n",
        "print(f\"wrote out-of-domain metrics to {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run In-Domain Calibration Transfer Evaluations"
      ],
      "metadata": {
        "id": "uBohTtp2fb3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_domain_transfer_results = []\n",
        "for cal_test_class_name in tqdm.tqdm(class_names):\n",
        "    print(f\"Evaluating transfer of in-domain calibrators (i.e. trained on other classes in Places365) to {cal_test_class_name} calibration test set\")\n",
        "    cal_test_class_id = class_ids[cal_test_class_name]\n",
        "    cal_test_class_name_clean = places365_clean_label(cal_test_class_name)\n",
        "    cal_test = in_domain_calibration_test_sets[cal_test_class_name]\n",
        "    eval_slug = f\"eval--{cal_test_class_id:>02}--{cal_test_class_name}--xfer\"\n",
        "    labels = cal_test[\"label\"]\n",
        "    for cal_train_class_name in tqdm.tqdm(class_names):\n",
        "        # could skip when train == test, but keep as a sanity test for now\n",
        "        # if cal_train_class_name == cal_test_class_name:\n",
        "        #     continue\n",
        "        cal_train_class_id = class_ids[cal_train_class_name]\n",
        "        cal_train_class_name_clean = places365_clean_label(cal_train_class_name)\n",
        "        for calibration_method in calibration_methods:\n",
        "            if calibration_method == \"SBA\":\n",
        "                # skip SBA since it cannot transfer in-domain (non-parameteric)\n",
        "                continue\n",
        "            cal_slug = f\"places365--{cal_train_class_id:>02}--{cal_train_class_name}--{calibration_method}\"\n",
        "            calibrator = calibrators[cal_slug]\n",
        "            probs = calibrator.predict_proba(cal_test[\"score\"])\n",
        "            preds = probs >= 0.5\n",
        "            results_slug = f\"{eval_slug}--{cal_train_class_id:>02}--{cal_train_class_name}--indomain\"\n",
        "            results = {\n",
        "                # classifier/calibrator metadata\n",
        "                \"model_name\": model_name,\n",
        "                \"provider\": provider,\n",
        "                \"calibration_method\": calibration_method,\n",
        "                \"train_class_id\": cal_train_class_id,\n",
        "                \"train_class_name\": cal_train_class_name,\n",
        "                \"train_class_name_clean\": cal_train_class_name_clean,\n",
        "                \"test_class_id\": cal_test_class_id,\n",
        "                \"test_class_name\": cal_test_class_name,\n",
        "                \"test_class_name_clean\": cal_test_class_name_clean,\n",
        "                \"test_class_domain\": \"xfer\",\n",
        "                \"slug\": results_slug,\n",
        "                # in-domain class-transfer classifier metrics\n",
        "                \"accuracy\": sklearn.metrics.accuracy_score(labels, preds),\n",
        "                \"precision\": sklearn.metrics.precision_score(labels, preds),\n",
        "                \"recall\": sklearn.metrics.recall_score(labels, preds),\n",
        "                \"f1\": sklearn.metrics.f1_score(labels, preds),\n",
        "                # in-domain class-transfer calibration metrics\n",
        "                \"brier_score\": sklearn.metrics.brier_score_loss(labels, probs),\n",
        "                \"sm_ece\": relplot.smECE(probs, labels),\n",
        "                \"binned_ece\": relplot.metrics.binnedECE(probs, labels, nbins=15),\n",
        "            }\n",
        "            in_domain_transfer_results.append(results)\n",
        "            show = False\n",
        "            make_plots = False\n",
        "            if make_plots:\n",
        "                sklearn.metrics.ConfusionMatrixDisplay.from_predictions(labels, preds)\n",
        "                plt.savefig(plots_dir / f\"{results_slug}-cm.png\", bbox_inches=\"tight\")\n",
        "                plt.show() if show else plt.close()\n",
        "                relplot.rel_diagram(probs, labels)\n",
        "                plt.savefig(plots_dir / f\"{results_slug}-relplot.png\", bbox_inches=\"tight\")\n",
        "                plt.show() if show else plt.close()\n",
        "                relplot.rel_diagram_binned(probs, labels)\n",
        "                plt.savefig(plots_dir / f\"{results_slug}-relplot-binned.png\", bbox_inches=\"tight\")\n",
        "                plt.show() if show else plt.close()\n",
        "xfer_df = pd.DataFrame(in_domain_transfer_results)\n",
        "save_path = results_dir / f\"metrics--xfer.csv\"\n",
        "xfer_df.to_csv(save_path)\n",
        "print(f\"wrote in-domain transfer metrics to {save_path}\")"
      ],
      "metadata": {
        "id": "S49xNxKDfREl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zip -r results results"
      ],
      "metadata": {
        "id": "2E-UUMXTmEig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b9_1ZO2yYpb"
      },
      "source": [
        "## Analyze Results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model_name, provider = \"ViT-B-32-quickgelu\", \"openai\"\n",
        "model_name, provider = \"ViT-B-16-SigLIP\", \"webli\"\n",
        "model_slug = f\"{model_name}--{provider}\"\n",
        "results_dir = pathlib.Path(\"/content/results\") / model_slug\n",
        "\n",
        "in_domain_df = pd.read_csv(results_dir / \"metrics--indomain.csv\")\n",
        "ood_df = pd.read_csv(results_dir / \"metrics--ood.csv\")\n",
        "xfer_df = pd.read_csv(results_dir / \"metrics--xfer.csv\")\n",
        "\n",
        "combined_df = pd.concat([in_domain_df, ood_df, xfer_df])\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_context(\"notebook\", font_scale=1.2)"
      ],
      "metadata": {
        "id": "mhqfBfiDkdQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_stats = combined_df.groupby([\"calibration_method\", \"test_class_domain\"])[[\"sm_ece\", \"accuracy\"]].mean()\n",
        "summary_stats[\"accuracy\"] = summary_stats[\"accuracy\"].apply(lambda x: f\"{x:.1%}\")\n",
        "summary_stats = summary_stats.reindex([\n",
        "    (\"sigmoid\", \"indomain\"),\n",
        "    (\"sigmoid\", \"ood\"),\n",
        "    (\"sigmoid\", \"xfer\"),\n",
        "    (\"isotonic\", \"indomain\"),\n",
        "    (\"isotonic\", \"ood\"),\n",
        "    (\"isotonic\", \"xfer\"),\n",
        "    (\"siglip\", \"indomain\"),\n",
        "    (\"siglip\", \"ood\"),\n",
        "    (\"siglip\", \"xfer\"),\n",
        "    (\"SBA\", \"indomain\"),\n",
        "    (\"SBA\", \"ood\"),\n",
        "])\n",
        "summary_stats = summary_stats.rename(index={\n",
        "    \"indomain\": \"In Domain\",\n",
        "    \"ood\": \"Out of Domain\",\n",
        "    \"sigmoid\": \"Sigmoid\",\n",
        "    \"isotonic\": \"Iso. Reg.\",\n",
        "    \"SBA\": \"SBA\",\n",
        "    \"siglip\": \"SigLIP\",\n",
        "    \"xfer\": \"Cross Class\",\n",
        "})\n",
        "summary_stats.index = summary_stats.index.set_names([\"Calibration Method\", \"Condition\"])\n",
        "summary_stats = summary_stats.rename(columns={\n",
        "    \"sm_ece\": \"SmoothECE\",\n",
        "    \"accuracy\": \"Accuracy\"\n",
        "})\n",
        "summary_stats = summary_stats.round(3)\n",
        "summary_stats"
      ],
      "metadata": {
        "id": "doy_AkMc1OfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "order = [\"sigmoid\", \"isotonic\", \"siglip\", \"SBA\"] if \"siglip\" in model_name.lower() else [\"sigmoid\", \"isotonic\", \"SBA\",]\n",
        "display_names = [\"Sigmoid\", \"Iso. Reg.\", \"SigLIP\", \"SBA\"] if \"siglip\" in model_name.lower() else [\"Sigmoid\", \"Iso. Reg.\", \"SBA\"]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    data=combined_df,\n",
        "    x=\"calibration_method\",\n",
        "    order=order,\n",
        "    y=\"sm_ece\",\n",
        "    hue=\"test_class_domain\",\n",
        "    hue_order=[\"indomain\", \"ood\", \"xfer\"],\n",
        "    palette=\"pastel\"\n",
        ")\n",
        "#plt.bar_label(plt.gca().containers[0], fmt=\"%.3f\", label_type=\"edge\")\n",
        "#plt.bar_label(plt.gca().containers[1], fmt=\"%.3f\", label_type=\"edge\")\n",
        "plt.title(f\"Calibration Performance Across Domains for {model_name}\", pad=20)\n",
        "plt.ylabel(\"SmoothECE\", labelpad=10)\n",
        "plt.xticks(range(4 if \"siglip\" in model_name.lower() else 3), display_names, ha=\"center\")\n",
        "plt.xlabel(\"Calibration Method\", labelpad=10)\n",
        "boxes, _ = plt.gca().get_legend_handles_labels()\n",
        "plt.legend(boxes, [\"In Domain\", \"Out of Domain\", \"Cross Class\"], bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(results_dir / \"plot-calibrations.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A8VL04yesnv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    data=combined_df,\n",
        "    x=\"calibration_method\",\n",
        "    order=order,\n",
        "    y=\"accuracy\",\n",
        "    hue=\"test_class_domain\",\n",
        "    hue_order=[\"indomain\", \"ood\", \"xfer\"],\n",
        "    palette=\"pastel\"\n",
        ")\n",
        "plt.title(f\"Accuracy Across Domains for {model_name}\", pad=20)\n",
        "plt.ylabel(\"Accuracy\", labelpad=10)\n",
        "plt.xticks(range(4 if \"siglip\" in model_name.lower() else 3), display_names, ha=\"center\")\n",
        "plt.xlabel(\"Calibration Method\", labelpad=10)\n",
        "boxes, _ = plt.gca().get_legend_handles_labels()\n",
        "plt.legend(boxes, [\"In Domain\", \"Out of Domain\", \"Cross Class\"], bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(results_dir / \"plot-accuracies.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kxrjXLJ7wWI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1kUDKr88YfH"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "colors = [\"#1f77b4\", \"#2ca02c\", \"#ff7f0e\", \"#d44674\"] if \"siglip\" in model_name.lower() else [\"#1f77b4\", \"#2ca02c\", \"#d44674\"]\n",
        "markers = [\"o\", \"s\", \"^\", \"x\"] if \"siglip\" in model_name.lower() else [\"o\", \"s\", \"x\"]\n",
        "\n",
        "for method, color, marker in zip(order, colors, markers):\n",
        "    method_data = in_domain_df[in_domain_df[\"calibration_method\"] == method]\n",
        "    plt.scatter(\n",
        "        method_data[\"sm_ece\"],\n",
        "        method_data[\"accuracy\"],\n",
        "        label=method,\n",
        "        alpha=0.7,\n",
        "        c=color,\n",
        "        marker=marker,\n",
        "        s=100\n",
        "    )\n",
        "\n",
        "    z = np.polyfit(method_data[\"sm_ece\"], method_data[\"accuracy\"], 1)\n",
        "    p = np.poly1d(z)\n",
        "    plt.plot(\n",
        "        method_data[\"sm_ece\"],\n",
        "        p(method_data[\"sm_ece\"]),\n",
        "        c=color,\n",
        "        linestyle=\"--\",\n",
        "        alpha=0.5\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"smECE\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(f\"Accuracy vs smECE by Calibration Method for {model_name}\")\n",
        "plt.legend()\n",
        "boxes, _ = plt.gca().get_legend_handles_labels()\n",
        "plt.legend(boxes, [\"Sigmoid\", \"Iso. Reg.\", \"SigLIP\", \"SBA\"], title=\"Calibration Method\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(results_dir / \"plot-calibrations-vs-accuracies.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtwheK9F-Esy"
      },
      "outputs": [],
      "source": [
        "! rm results.zip\n",
        "! zip -r results results"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQtkPAyjFic7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPAVlNczNOGlOoUpE4wbj4+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}