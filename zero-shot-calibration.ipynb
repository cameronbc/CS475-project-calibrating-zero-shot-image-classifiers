{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMcPlsHpD5x71iKi6blnNOl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEjKStTfw5lC"
      },
      "outputs": [],
      "source": [
        "! pip install open_clip_torch\n",
        "! pip install --upgrade datasets\n",
        "! pip install relplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import open_clip\n",
        "import PIL.Image\n",
        "import PIL.PngImagePlugin\n",
        "import relplot\n",
        "import scipy.special\n",
        "import sklearn.calibration\n",
        "import sklearn.isotonic\n",
        "import sklearn.metrics\n",
        "import torch\n",
        "\n",
        "PIL.PngImagePlugin.MAX_TEXT_CHUNK = 100 * (1024**2)"
      ],
      "metadata": {
        "id": "jFTaNWWv05WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "DATASET_URLS = {\n",
        "    \"llama-test\": \"https://drive.google.com/uc?id=1pop_ltmF9mpiMDqi1lcTbpmOyTo96if1\",\n",
        "    \"llama-train\": \"https://drive.google.com/uc?id=1Wyc8U_I2UCjT863ndpDfhgSLxjfArk3A\",\n",
        "    \"beach-train\": \"https://drive.google.com/uc?id=1F6ozO15919KpPP_57Z0jD5dHOqU_w-nb\",\n",
        "    \"beach-test\": \"https://drive.google.com/uc?id=1o5MpdWKKrC80I4zbJr9u2L_zKPUXdQgy\",\n",
        "    \"beach-test-ood\": \"https://drive.google.com/uc?id=163NyfmWarIAAOjUqH3QPedQokzfmNoFH\",\n",
        "}"
      ],
      "metadata": {
        "id": "Xwyu2pvIxDz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset_name, dataset_gdrive_url in DATASET_URLS.items():\n",
        "    ! gdown {dataset_gdrive_url}\n",
        "    ! unzip /content/{dataset_name}.zip"
      ],
      "metadata": {
        "id": "tUKd0snOr_qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ZeroShotClassifier:\n",
        "    \"\"\"Wrapper for loading and running zero-shot image classifiers.\"\"\"\n",
        "\n",
        "    TEMPLATES = [\n",
        "        \"itap of a {}.\",\n",
        "        \"a bad photo of the {}.\",\n",
        "        \"a origami {}.\",\n",
        "        \"a photo of the large {}.\",\n",
        "        \"a {} in a video game.\",\n",
        "        \"art of the {}.\",\n",
        "        \"a photo of the small {}.\",\n",
        "    ]\n",
        "\n",
        "    def __init__(self, model_name, pretrained_source, device):\n",
        "        self.model_name = model_name\n",
        "        self.pretrained_source = pretrained_source\n",
        "        self.device = device\n",
        "        self.model, _, self.preprocess = open_clip.create_model_and_transforms(\n",
        "            self.model_name,\n",
        "            pretrained=self.pretrained_source,\n",
        "        )\n",
        "        self.model.eval().to(device)\n",
        "        self.tokenizer = open_clip.get_tokenizer(self.model_name)\n",
        "        self.text = None\n",
        "        self.text_features = None\n",
        "\n",
        "    def set_text(self, text):\n",
        "        self.text = text\n",
        "        tokens = self.tokenizer([t.format(self.text) for t in ZeroShotClassifier.TEMPLATES])\n",
        "        with torch.no_grad(), torch.amp.autocast(\"cuda\"):\n",
        "            text_features = self.model.encode_text(tokens.to(self.device))\n",
        "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "            text_features = text_features.mean(dim=0)\n",
        "            text_features /= text_features.norm()\n",
        "        self.text_features = text_features.to(\"cpu\").numpy()\n",
        "\n",
        "    def get_image_features(self, image: PIL.Image.Image):\n",
        "        input_features = self.preprocess(image).unsqueeze(0)\n",
        "        with torch.no_grad(), torch.amp.autocast(\"cuda\"):\n",
        "            image_features = self.model.encode_image(input_features.to(self.device))\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        return image_features.to(\"cpu\").numpy()\n",
        "\n",
        "    def get_image_features_batch(self, images):\n",
        "        input_features = torch.stack([self.preprocess(im) for im in images])\n",
        "        with torch.no_grad(), torch.amp.autocast(\"cuda\"):\n",
        "            image_features = self.model.encode_image(input_features.to(self.device))\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        return image_features.cpu().numpy()\n",
        "\n",
        "    def score_image(self, image: PIL.Image.Image, with_features: bool = False):\n",
        "        image_features = self.get_image_features(image)\n",
        "        score = (image_features @ self.text_features).item()\n",
        "        results = {\"score\": score.astype(np.float32)}\n",
        "        if with_features:\n",
        "            results[\"features\"] = image_features\n",
        "        return results\n",
        "\n",
        "    def score_image_batch(self, images, with_features=False):\n",
        "        image_features = self.get_image_features_batch(images)\n",
        "        scores = image_features @ self.text_features\n",
        "        results = {\"score\": scores.astype(np.float32)}\n",
        "        if with_features:\n",
        "            results[\"features\"] = image_features\n",
        "        return results\n",
        "\n",
        "class BaseCalibrator:\n",
        "    \"\"\"Base class for score calibration methods.\"\"\"\n",
        "\n",
        "    def fit(self, scores: np.ndarray, labels: np.ndarray):\n",
        "        \"\"\"Train the calibrator.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Calibrate scores into probabilities.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class IsotonicCalibrator(BaseCalibrator):\n",
        "    \"\"\"Calibrates scores using isotonic regression.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.calibrator = sklearn.isotonic.IsotonicRegression(out_of_bounds=\"clip\")\n",
        "\n",
        "    def fit(self, scores: np.ndarray, labels: np.ndarray) -> \"IsotonicCalibrator\":\n",
        "        \"\"\"Fit the isotonic calibrator.\"\"\"\n",
        "        self.calibrator.fit(scores, labels)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply isotonic calibration to scores.\"\"\"\n",
        "        return self.calibrator.predict(scores)\n",
        "\n",
        "\n",
        "class SigmoidCalibrator(BaseCalibrator):\n",
        "    \"\"\"Calibrates scores using sigmoid/Platt scaling.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.calibrator = sklearn.calibration._SigmoidCalibration() # brittle\n",
        "\n",
        "    def fit(self, scores: np.ndarray, labels: np.ndarray) -> \"SigmoidCalibrator\":\n",
        "        \"\"\"Fit the sigmoid calibrator\"\"\"\n",
        "        self.calibrator.fit(scores, labels)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply sigmoid calibration to scores.\"\"\"\n",
        "        return self.calibrator.predict(scores)\n",
        "\n",
        "\n",
        "class SimilarityBinningAveragingCalibrator(BaseCalibrator):\n",
        "    \"\"\"Calibrates scores using Similarity-Binning Averaging calibration.\"\"\"\n",
        "\n",
        "    def __init__(self, k: int=10, alpha: float=0.95, inner_calibration_class: BaseCalibrator=SigmoidCalibrator) -> None:\n",
        "        \"\"\"Create a new instance of the SBA calibrator.\n",
        "\n",
        "        k: number of nearest neighbors in the bin to average over\n",
        "        alpha: weighting factor between CLIP features and class probs for similarity\n",
        "        inner_calibration_class: method for getting calibrated scores from calibration data\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "        self.alpha = alpha\n",
        "        self.inner_calibrator = inner_calibration_class()\n",
        "        self._train_features = None\n",
        "        self._train_probs = None\n",
        "\n",
        "    def fit(self, scores: np.ndarray, labels: np.ndarray, features: np.ndarray) -> \"SigmoidCalibrator\":\n",
        "        \"\"\"Fit the sigmoid calibrator\"\"\"\n",
        "        self.inner_calibrator.fit(scores, labels)\n",
        "        self._train_features = features\n",
        "        self._train_probs = self.inner_calibrator.predict_proba(scores)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray, features: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply sigmoid calibration to scores.\"\"\"\n",
        "        feature_similarities = features @ self._train_features.T\n",
        "        fs_max = feature_similarities.max()\n",
        "        fs_min = feature_similarities.min()\n",
        "        feature_similarities = (feature_similarities - fs_min) / fs_max\n",
        "        probs = self.inner_calibrator.predict_proba(scores)\n",
        "        probs_similarities = 1 - np.abs(probs[:, np.newaxis] - self._train_probs)\n",
        "        similarities = self.alpha * feature_similarities + (1 - self.alpha) * probs_similarities\n",
        "        top_k_indices = np.argsort(-similarities, axis=1)[:, :self.k]\n",
        "        top_k_probs = self._train_probs[top_k_indices]\n",
        "        return top_k_probs.mean(axis=1)"
      ],
      "metadata": {
        "id": "3jfxqtZY1iNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_scores_dataset(zero_shot_classifier, image_dataset, batch_size=32, with_features=False):\n",
        "    scores_dataset = image_dataset.map(\n",
        "        lambda examples: dict(\n",
        "            label=examples[\"label\"],\n",
        "            **zero_shot_classifier.score_image_batch(examples[\"image\"], with_features)\n",
        "        ),\n",
        "        remove_columns=[\"image\"],\n",
        "        batched=True,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    scores_dataset.set_format(type=\"numpy\", columns=[\"features\",])\n",
        "    return scores_dataset"
      ],
      "metadata": {
        "id": "HUO_2bH417Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "batch_size = 32\n",
        "zsc = ZeroShotClassifier(\"ViT-B-32-quickgelu\", \"openai\", device)\n",
        "#zsc = ZeroShotClassifier(\"ViT-B-16-SigLIP\", \"webli\")\n",
        "labels = [\"beach\"]\n",
        "for label in labels:\n",
        "    zsc.set_text(label)\n",
        "\n",
        "    train_image_dataset_path = pathlib.Path(f\"/content/{label}-train\")\n",
        "    train_image_dataset = datasets.load_from_disk(train_image_dataset_path)\n",
        "    train_scores_dataset = build_scores_dataset(zsc, train_image_dataset, batch_size=batch_size, with_features=True)\n",
        "\n",
        "    test_image_dataset_path = pathlib.Path(f\"/content/{label}-test-ood\")\n",
        "    test_image_dataset = datasets.load_from_disk(test_image_dataset_path)\n",
        "    test_scores_dataset = build_scores_dataset(zsc, test_image_dataset, batch_size=batch_size, with_features=True)\n",
        "\n",
        "    calibration_methods = [\"sigmoid\", \"isotonic\", \"sba\"]\n",
        "    for calibration_method in calibration_methods:\n",
        "        if calibration_method == \"sigmoid\":\n",
        "            calibrator = SigmoidCalibrator()\n",
        "            calibrator.fit(train_scores_dataset[\"score\"], train_scores_dataset[\"label\"])\n",
        "            probs = calibrator.predict_proba(test_scores_dataset[\"score\"])\n",
        "        elif calibration_method == \"isotonic\":\n",
        "            calibrator = IsotonicCalibrator()\n",
        "            calibrator.fit(train_scores_dataset[\"score\"], train_scores_dataset[\"label\"])\n",
        "            probs = calibrator.predict_proba(test_scores_dataset[\"score\"])\n",
        "        elif calibration_method == \"sba\":\n",
        "            calibrator = SimilarityBinningAveragingCalibrator()\n",
        "            calibrator.fit(train_scores_dataset[\"score\"], train_scores_dataset[\"label\"], train_scores_dataset[\"features\"])\n",
        "            probs = calibrator.predict_proba(test_scores_dataset[\"score\"], test_scores_dataset[\"features\"])\n",
        "\n",
        "        print(f\"Calibration results for '{label}' with {calibration_method} calibration\")\n",
        "        sklearn.metrics.ConfusionMatrixDisplay.from_predictions(test_scores_dataset[\"label\"], probs > 0.5)\n",
        "        brier_score = sklearn.metrics.brier_score_loss(test_scores_dataset[\"label\"], probs)\n",
        "        print(f\"Brier score: {brier_score:.4f}\")\n",
        "        sm_ece = relplot.smECE(probs, test_scores_dataset[\"label\"])\n",
        "        print(f\"smECE: {sm_ece:.4f}\")\n",
        "        relplot.rel_diagram(probs, test_scores_dataset[\"label\"])\n",
        "        plt.show()\n",
        "        relplot.rel_diagram_binned(probs, test_scores_dataset[\"label\"])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "-agzSrkqxVd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JR8oppgmMcy-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}