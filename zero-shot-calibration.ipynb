{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFDDTVIfrR1X"
      },
      "source": [
        "# Experiments in Calibrating Zero-Shot Image Classifiers\n",
        "\n",
        "This notebooks contains code for experimenting with different calibration methods for binary classifiers, applied to the use case of zero-shot image classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfhsUvCmrnA6"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! sudo apt install dvipng texlive-latex-extra texlive-fonts-recommended texlive-fonts-extra cm-super\n",
        "! pip install --upgrade datasets open_clip_torch relplot"
      ],
      "metadata": {
        "id": "gtJDwDynjCz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96pbjsP1rsTD"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFTaNWWv05WA"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import open_clip\n",
        "import pandas as pd\n",
        "import PIL.Image\n",
        "import PIL.PngImagePlugin\n",
        "import relplot\n",
        "import scipy.special\n",
        "import sklearn.calibration\n",
        "import sklearn.isotonic\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import torch\n",
        "import tqdm.auto as tqdm\n",
        "\n",
        "# fix image loading errors for some large files\n",
        "PIL.PngImagePlugin.MAX_TEXT_CHUNK = 100 * (1024**2)\n",
        "\n",
        "# have relplot make pretty LaTeX axis labels\n",
        "relplot.config.use_tex_fonts = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8pgo3-6rzoB"
      },
      "source": [
        "## Fetch Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xwyu2pvIxDz2"
      },
      "outputs": [],
      "source": [
        "DATASET_URLS = {\n",
        "    # Aerial Image Dataset: https://captain-whu.github.io/AID/\n",
        "    \"aid\": \"https://drive.google.com/uc?id=1CTdCFoo88_ygMb2PNGnK3QTi8xk_naoA\",\n",
        "    # MIT Places 365: http://places2.csail.mit.edu/\n",
        "    \"places365\": \"https://drive.google.com/uc?id=1w-0LncVMfBsdtqX7jT-jCTdAnLBZuFtU\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUKd0snOr_qn"
      },
      "outputs": [],
      "source": [
        "for dataset_name, dataset_gdrive_url in DATASET_URLS.items():\n",
        "    ! gdown {dataset_gdrive_url}\n",
        "    ! mkdir {dataset_name}\n",
        "    ! unzip /content/{dataset_name}.zip -d {dataset_name}\n",
        "    ! rm /content/{dataset_name}.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iorWHMMmsAcu"
      },
      "source": [
        "## Implement Zero-Shot Classifier and Calibrators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jfxqtZY1iNk"
      },
      "outputs": [],
      "source": [
        "class ZeroShotClassifier:\n",
        "    \"\"\"Wrapper for loading and running zero-shot image classifiers.\"\"\"\n",
        "\n",
        "    TEMPLATES = [\n",
        "        \"itap of a {}.\",\n",
        "        \"a bad photo of the {}.\",\n",
        "        \"a origami {}.\",\n",
        "        \"a photo of the large {}.\",\n",
        "        \"a {} in a video game.\",\n",
        "        \"art of the {}.\",\n",
        "        \"a photo of the small {}.\",\n",
        "    ]\n",
        "\n",
        "    def __init__(self, model_name, pretrained_source, device):\n",
        "        \"\"\"Create a new instance of the zero-shot classifier.\"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.pretrained_source = pretrained_source\n",
        "        self.device = device\n",
        "        self.model, _, self.preprocess = open_clip.create_model_and_transforms(\n",
        "            self.model_name,\n",
        "            pretrained=self.pretrained_source,\n",
        "        )\n",
        "        self.model.eval().to(device)\n",
        "        self.tokenizer = open_clip.get_tokenizer(self.model_name)\n",
        "        self.text = None\n",
        "        self.text_features = None\n",
        "\n",
        "    def set_text(self, text):\n",
        "        \"\"\"Set the text prompt for the classifier.\"\"\"\n",
        "        self.text = text\n",
        "        tokens = self.tokenizer(\n",
        "            [t.format(self.text) for t in ZeroShotClassifier.TEMPLATES]\n",
        "        )\n",
        "        with torch.no_grad(), torch.amp.autocast(\"cuda\"):\n",
        "            text_features = self.model.encode_text(tokens.to(self.device))\n",
        "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "            text_features = text_features.mean(dim=0)\n",
        "            text_features /= text_features.norm()\n",
        "        self.text_features = text_features.to(\"cpu\").numpy()\n",
        "\n",
        "    def get_image_features(self, image: PIL.Image.Image):\n",
        "        \"\"\"Get CLIP features for a single image.\"\"\"\n",
        "        input_features = self.preprocess(image).unsqueeze(0)\n",
        "        with torch.no_grad(), torch.amp.autocast(\"cuda\"):\n",
        "            image_features = self.model.encode_image(input_features.to(self.device))\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        return image_features.to(\"cpu\").numpy()\n",
        "\n",
        "    def get_image_features_batch(self, images):\n",
        "        \"\"\"Get CLIP features for a batch of images.\"\"\"\n",
        "        input_features = torch.stack([self.preprocess(im) for im in images])\n",
        "        with torch.no_grad(), torch.amp.autocast(\"cuda\"):\n",
        "            image_features = self.model.encode_image(input_features.to(self.device))\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        return image_features.cpu().numpy()\n",
        "\n",
        "    def score_image(self, image: PIL.Image.Image, with_features: bool = False):\n",
        "        \"\"\"Score an image based on the text prompt.\"\"\"\n",
        "        image_features = self.get_image_features(image)\n",
        "        score = (image_features @ self.text_features).item()\n",
        "        results = {\"score\": score.astype(np.float32)}\n",
        "        if with_features:\n",
        "            results[\"features\"] = image_features\n",
        "        return results\n",
        "\n",
        "    def score_image_batch(self, images, with_features=False):\n",
        "        \"\"\"Score a batch of images based on the text prompt.\"\"\"\n",
        "        image_features = self.get_image_features_batch(images)\n",
        "        scores = image_features @ self.text_features\n",
        "        results = {\"score\": scores.astype(np.float32)}\n",
        "        if with_features:\n",
        "            results[\"features\"] = image_features\n",
        "        return results\n",
        "\n",
        "    def score_features(self, image_features: np.ndarray):\n",
        "        \"\"\"Score image features based on the text prompt.\"\"\"\n",
        "        score = (image_features @ self.text_features).item()\n",
        "        return score.astype(np.float32)\n",
        "\n",
        "    def score_features_batch(self, image_features: np.ndarray):\n",
        "        \"\"\"Score a batch of image features based on the text prompt.\"\"\"\n",
        "        scores = image_features @ self.text_features\n",
        "        return scores.astype(np.float32)\n",
        "\n",
        "\n",
        "class BaseCalibrator:\n",
        "    \"\"\"Base class for score calibration methods.\"\"\"\n",
        "\n",
        "    def fit(self, scores: np.ndarray, labels: np.ndarray):\n",
        "        \"\"\"Train the calibrator.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Calibrate scores into probabilities.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class IsotonicCalibrator(BaseCalibrator):\n",
        "    \"\"\"Calibrate scores using isotonic regression.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Create a new instance of the isotonic calibrator.\"\"\"\n",
        "        self.calibrator = sklearn.isotonic.IsotonicRegression(out_of_bounds=\"clip\")\n",
        "\n",
        "    def fit(self, scores: np.ndarray, labels: np.ndarray) -> \"IsotonicCalibrator\":\n",
        "        \"\"\"Fit the isotonic calibrator.\"\"\"\n",
        "        self.calibrator.fit(scores, labels)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply isotonic calibration to scores.\"\"\"\n",
        "        return self.calibrator.predict(scores)\n",
        "\n",
        "\n",
        "class SigmoidCalibrator(BaseCalibrator):\n",
        "    \"\"\"Calibrates scores using sigmoid/Platt scaling.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Create a new instance of the sigmoid calibrator.\"\"\"\n",
        "        self.calibrator = sklearn.calibration._SigmoidCalibration()  # brittle\n",
        "\n",
        "    def fit(self, scores: np.ndarray, labels: np.ndarray) -> \"SigmoidCalibrator\":\n",
        "        \"\"\"Fit the sigmoid calibrator\"\"\"\n",
        "        self.calibrator.fit(scores, labels)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply sigmoid calibration to scores.\"\"\"\n",
        "        return self.calibrator.predict(scores)\n",
        "\n",
        "\n",
        "class SimilarityBinningAveragingCalibrator(BaseCalibrator):\n",
        "    \"\"\"Calibrate scores using Similarity-Binning Averaging calibration.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        k: int = 10,\n",
        "        alpha: float = 0.95,\n",
        "        inner_calibration_class: BaseCalibrator = SigmoidCalibrator,\n",
        "    ) -> None:\n",
        "        \"\"\"Create a new instance of the SBA calibrator.\n",
        "\n",
        "        k: number of nearest neighbors in the bin to average over\n",
        "        alpha: weighting factor between CLIP features and class probs for similarity\n",
        "        inner_calibration_class: method for getting calibrated scores from calibration data\n",
        "        \"\"\"\n",
        "        self.k = k\n",
        "        self.alpha = alpha\n",
        "        self.inner_calibrator = inner_calibration_class()\n",
        "        self._train_features = None\n",
        "        self._train_probs = None\n",
        "\n",
        "    def fit(\n",
        "        self, scores: np.ndarray, labels: np.ndarray, features: np.ndarray\n",
        "    ) -> \"SimilarityBinningAveragingCalibrator\":\n",
        "        \"\"\"Fit the SBA calibrator\"\"\"\n",
        "        self.inner_calibrator.fit(scores, labels)\n",
        "        self._train_features = features\n",
        "        self._train_probs = self.inner_calibrator.predict_proba(scores)\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, scores: np.ndarray, features: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Apply SBA calibration to scores.\"\"\"\n",
        "        feature_similarities = features @ self._train_features.T\n",
        "        fs_max = feature_similarities.max()\n",
        "        fs_min = feature_similarities.min()\n",
        "        feature_similarities = (feature_similarities - fs_min) / fs_max\n",
        "        probs = self.inner_calibrator.predict_proba(scores)\n",
        "        probs_similarities = 1 - np.abs(probs[:, np.newaxis] - self._train_probs)\n",
        "        similarities = (\n",
        "            self.alpha * feature_similarities + (1 - self.alpha) * probs_similarities\n",
        "        )\n",
        "        top_k_indices = np.argsort(-similarities, axis=1)[:, : self.k]\n",
        "        top_k_probs = self._train_probs[top_k_indices]\n",
        "        return top_k_probs.mean(axis=1)\n",
        "\n",
        "\n",
        "def build_features_dataset(zero_shot_classifier, image_dataset, batch_size=32):\n",
        "    \"\"\"Compute and add extracted CLIP features as a column in an image dataset.\"\"\"\n",
        "    features_dataset = image_dataset.map(\n",
        "        lambda images: dict(\n",
        "            features=zero_shot_classifier.get_image_features_batch(images)\n",
        "        ),\n",
        "        input_columns=[\"image\"],\n",
        "        batched=True,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    return features_dataset\n",
        "\n",
        "\n",
        "def build_scores_dataset(zero_shot_classifier, features_dataset, batch_size=1024):\n",
        "    \"\"\"Compute and add zero-shot scores as a column in a features dataset.\"\"\"\n",
        "    def compute_scores(features):\n",
        "        return {\n",
        "            \"score\": zero_shot_classifier.score_features_batch(features),\n",
        "        }\n",
        "    scores_dataset = features_dataset.map(\n",
        "        compute_scores,\n",
        "        input_columns=[\"features\"],\n",
        "        batched=True,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    return scores_dataset\n",
        "\n",
        "\n",
        "def places365_clean_label(label):\n",
        "    \"\"\"Clean up Places365 labels for use in zero-shot prompting.\"\"\"\n",
        "    if \"-\" in label:\n",
        "        noun, adj = label.rsplit(\"-\", 1)\n",
        "        label = f\"{adj} {noun}\"\n",
        "    return label.replace(\"_\", \" \")\n",
        "\n",
        "\n",
        "def create_binary_dataset(\n",
        "    multiclass_dataset: datasets.Dataset,\n",
        "    target_class_id: int,\n",
        "    non_target_ratio: float = 2.0,\n",
        "):\n",
        "    \"\"\"Create a binary dataset from a multiclass dataset.\n",
        "\n",
        "    The binary dataset will have a target class and a non-target class, with the\n",
        "    non-target class sampled at a specified ratio to the target class.\n",
        "    \"\"\"\n",
        "    num_target_samples = sum(\n",
        "        label == target_class_id for label in multiclass_dataset[\"label\"]\n",
        "    )\n",
        "    num_non_target_samples = len(multiclass_dataset) - num_target_samples\n",
        "    non_target_prob = non_target_ratio * num_target_samples / num_non_target_samples\n",
        "\n",
        "    def filter_dataset(labels_batch):\n",
        "        keep = []\n",
        "        for label in labels_batch:\n",
        "            if label == target_class_id:\n",
        "                keep.append(True)\n",
        "            else:\n",
        "                if np.random.random() < non_target_prob:\n",
        "                    keep.append(True)\n",
        "                else:\n",
        "                    keep.append(False)\n",
        "        return keep\n",
        "\n",
        "    binary_dataset = multiclass_dataset.filter(\n",
        "        filter_dataset,\n",
        "        input_columns=[\"label\"],\n",
        "        batched=True,\n",
        "        batch_size=1024,\n",
        "    )\n",
        "    binary_dataset = binary_dataset.map(\n",
        "        lambda labels: dict(\n",
        "            label=np.array([int(label == target_class_id) for label in labels]),\n",
        "        ),\n",
        "        input_columns=[\"label\"],\n",
        "        batched=True,\n",
        "        batch_size=1024,\n",
        "    )\n",
        "    binary_dataset = binary_dataset.cast_column(\n",
        "        \"label\", datasets.ClassLabel(names=[\"non-target\", \"target\"])\n",
        "    )\n",
        "    return binary_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFPPG5RuvC8m"
      },
      "source": [
        "## Create Zero-Shot Classifier and Extract Image Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmpALZI_oP-R"
      },
      "outputs": [],
      "source": [
        "! mkdir -p /content/results\n",
        "! rm -rf /content/results/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDagCaOGqDe8"
      },
      "outputs": [],
      "source": [
        "print(\"Creating zero-shot classifier\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_name, provider = \"ViT-B-32-quickgelu\", \"openai\"\n",
        "#model_name, provider = \"ViT-B-16-SigLIP\", \"webli\"\n",
        "#model_name, provider = \"ViT-B-32\", \"datacomp_m_s128m_b4k\"\n",
        "#model_name, provider = \"RN50-quickgelu\", \"yfcc15m\"\n",
        "zsc = ZeroShotClassifier(model_name, provider, device)\n",
        "\n",
        "print(\"Extracting features for AID dataset\")\n",
        "aid_dataset = datasets.load_from_disk(\"/content/aid\", keep_in_memory=True)\n",
        "aid_dataset = build_features_dataset(zsc, aid_dataset)\n",
        "aid_dataset.set_format(type=\"numpy\")\n",
        "\n",
        "print(\"Extracting features for Places365 dataset (takes several minutes)\")\n",
        "places_dataset = datasets.load_from_disk(\"/content/places365\", keep_in_memory=True)\n",
        "places_dataset = build_features_dataset(zsc, places_dataset)\n",
        "places_dataset.set_format(type=\"numpy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsuCpFKGkNuw"
      },
      "source": [
        "## Run Zero-Shot Classification and Calibration and Collect Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR8oppgmMcy-"
      },
      "outputs": [],
      "source": [
        "results_dir = pathlib.Path(\"/content/results\")\n",
        "all_results = []\n",
        "calibrators = {}\n",
        "for target_class_name in tqdm.tqdm(places_dataset.features[\"label\"].names):\n",
        "    target_class_id = places_dataset.features[\"label\"].str2int(target_class_name)\n",
        "    target_class_name_clean = places365_clean_label(target_class_name)\n",
        "    print(f\"Processing {target_class_name_clean} (class {target_class_id}) from Places365\")\n",
        "    zsc.set_text(target_class_name_clean)\n",
        "\n",
        "    # make one-vs-rest version of dataset\n",
        "    # note, we filter out some non-targets to make the dataset more balanced\n",
        "    calibration_dataset = create_binary_dataset(places_dataset, target_class_id)\n",
        "    calibration_dataset = build_scores_dataset(zsc, calibration_dataset)\n",
        "    calibration_dataset = calibration_dataset.train_test_split(test_size=0.5, seed=42)\n",
        "\n",
        "    # use AID as the out-of-domain test set\n",
        "    ood_calibration_dataset = create_binary_dataset(aid_dataset, target_class_id)\n",
        "    ood_calibration_dataset = build_scores_dataset(zsc, ood_calibration_dataset)\n",
        "\n",
        "    for calibration_method in [\"sigmoid\", \"isotonic\", \"sba\"]:\n",
        "        calibrator_args = [\n",
        "            calibration_dataset[\"train\"][\"score\"],\n",
        "            calibration_dataset[\"train\"][\"label\"],\n",
        "        ]\n",
        "        predict_proba_args = [calibration_dataset[\"test\"][\"score\"]]\n",
        "        ood_predict_proba_args = [ood_calibration_dataset[\"score\"]]\n",
        "\n",
        "        if calibration_method == \"sigmoid\":\n",
        "            calibrator = SigmoidCalibrator()\n",
        "        elif calibration_method == \"isotonic\":\n",
        "            calibrator = IsotonicCalibrator()\n",
        "        elif calibration_method == \"sba\":\n",
        "            calibrator = SimilarityBinningAveragingCalibrator()\n",
        "            calibrator_args.append(calibration_dataset[\"train\"][\"features\"])\n",
        "            predict_proba_args.append(calibration_dataset[\"test\"][\"features\"])\n",
        "            ood_predict_proba_args.append(ood_calibration_dataset[\"features\"])\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown calibration method {calibration_method}\")\n",
        "\n",
        "        calibrator.fit(*calibrator_args)\n",
        "        labels = calibration_dataset[\"test\"][\"label\"]\n",
        "        probs = calibrator.predict_proba(*predict_proba_args)\n",
        "        preds = probs >= 0.5\n",
        "        ood_labels = ood_calibration_dataset[\"label\"]\n",
        "        ood_probs = calibrator.predict_proba(*ood_predict_proba_args)\n",
        "        ood_preds = ood_probs >= 0.5\n",
        "\n",
        "        slug = f\"{provider}--{model_name}--{target_class_id:>02}--{target_class_name}--{calibration_method}\"\n",
        "        calibrators[slug] = calibrator\n",
        "        print(f\"Computing plots and metrics for {slug}\")\n",
        "        results = {\n",
        "            # classifier/calibrator metadata\n",
        "            \"model_name\": model_name,\n",
        "            \"provider\": provider,\n",
        "            \"target_class_id\": target_class_id,\n",
        "            \"target_class_name\": target_class_name,\n",
        "            \"target_class_name_clean\": target_class_name_clean,\n",
        "            \"calibration_method\": calibration_method,\n",
        "            \"slug\": slug,\n",
        "            # in-domain classifier metrics\n",
        "            \"accuracy\": sklearn.metrics.accuracy_score(labels, preds),\n",
        "            \"precision\": sklearn.metrics.precision_score(labels, preds),\n",
        "            \"recall\": sklearn.metrics.recall_score(labels, preds),\n",
        "            \"f1\": sklearn.metrics.f1_score(labels, preds),\n",
        "            # in-domain calibration metrics\n",
        "            \"brier_score\": sklearn.metrics.brier_score_loss(labels, probs),\n",
        "            \"sm_ece\": relplot.smECE(probs, labels),\n",
        "            \"binned_ece\": relplot.metrics.binnedECE(probs, labels, nbins=15),\n",
        "            # out-of-domain classifier metrics\n",
        "            \"ood_accuracy\": sklearn.metrics.accuracy_score(ood_labels, ood_preds),\n",
        "            \"ood_precision\": sklearn.metrics.precision_score(ood_labels, ood_preds),\n",
        "            \"ood_recall\": sklearn.metrics.recall_score(ood_labels, ood_preds),\n",
        "            \"ood_f1\": sklearn.metrics.f1_score(ood_labels, ood_preds),\n",
        "            # out-of-domain calibration metrics\n",
        "            \"ood_brier_score\": sklearn.metrics.brier_score_loss(ood_labels, ood_probs),\n",
        "            \"ood_sm_ece\": relplot.smECE(ood_probs, ood_labels),\n",
        "            \"ood_binned_ece\": relplot.metrics.binnedECE(ood_probs, ood_labels, nbins=15),\n",
        "        }\n",
        "        all_results.append(results)\n",
        "\n",
        "        show = True\n",
        "        sklearn.metrics.ConfusionMatrixDisplay.from_predictions(labels, preds)\n",
        "        plt.savefig(results_dir / f\"{slug}-confusion_matrix.png\", bbox_inches=\"tight\")\n",
        "        plt.show() if show else plt.close()\n",
        "        relplot.rel_diagram(probs, labels)\n",
        "        plt.savefig(results_dir / f\"{slug}-reliability_diagram.png\", bbox_inches=\"tight\")\n",
        "        plt.show() if show else plt.close()\n",
        "        relplot.rel_diagram_binned(probs, labels)\n",
        "        plt.savefig(results_dir / f\"{slug}-reliability_diagram_binned.png\", bbox_inches=\"tight\")\n",
        "        plt.show() if show else plt.close()\n",
        "\n",
        "        sklearn.metrics.ConfusionMatrixDisplay.from_predictions(ood_labels, ood_preds)\n",
        "        plt.savefig(results_dir / f\"{slug}-ood-confusion_matrix.png\", bbox_inches=\"tight\")\n",
        "        plt.show() if show else plt.close()\n",
        "        relplot.rel_diagram(ood_probs, ood_labels)\n",
        "        plt.savefig(results_dir / f\"{slug}-ood-reliability_diagram.png\", bbox_inches=\"tight\")\n",
        "        plt.show() if show else plt.close()\n",
        "        relplot.rel_diagram_binned(ood_probs, ood_labels)\n",
        "        plt.savefig(results_dir / f\"{slug}-ood-reliability_diagram_binned.png\", bbox_inches=\"tight\")\n",
        "        plt.show() if show else plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b9_1ZO2yYpb"
      },
      "source": [
        "## Analyze Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcWg3LCryX7S"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(all_results)\n",
        "results_df.to_csv(results_dir / f\"metrics-{provider}-{model_name}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxXneEra2mPw"
      },
      "outputs": [],
      "source": [
        "results_df[\"calibration_method\"] = results_df[\"slug\"].str.split(\"--\").str[-1]\n",
        "overall_stats = (\n",
        "    results_df.groupby(\"calibration_method\")\n",
        "    .agg({\"sm_ece\": [\"mean\", \"std\"], \"ood_sm_ece\": [\"mean\", \"std\"]})\n",
        "    .round(4)\n",
        ")\n",
        "overall_stats[\"degradation\"] = (\n",
        "    overall_stats[(\"ood_sm_ece\", \"mean\")] / overall_stats[(\"sm_ece\", \"mean\")]\n",
        ").round(2)\n",
        "\n",
        "per_class_stats = (\n",
        "    results_df.groupby([\"target_class_name_clean\", \"calibration_method\"])\n",
        "    .agg({\"sm_ece\": \"mean\", \"ood_sm_ece\": \"mean\"})\n",
        "    .round(4)\n",
        ")\n",
        "per_class_stats[\"degradation\"] = (\n",
        "    per_class_stats[\"ood_sm_ece\"] / per_class_stats[\"sm_ece\"]\n",
        ").round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WVKnEAc7ev1"
      },
      "outputs": [],
      "source": [
        "overall_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEqQA-CS7ft5"
      },
      "outputs": [],
      "source": [
        "per_class_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef4Tudy671NB"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plot_data = pd.melt(\n",
        "    results_df,\n",
        "    id_vars=[\"calibration_method\"],\n",
        "    value_vars=[\"sm_ece\", \"ood_sm_ece\"],\n",
        "    var_name=\"metric\",\n",
        "    value_name=\"value\"\n",
        ")\n",
        "\n",
        "sns.boxplot(\n",
        "    data=plot_data,\n",
        "    x=\"calibration_method\",\n",
        "    y=\"value\",\n",
        "    hue=\"metric\",\n",
        ")\n",
        "plt.title(\"smECE Distribution by Calibration Method\")\n",
        "plt.ylabel(\"smECE Value\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1kUDKr88YfH"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "colors = [\"#1f77b4\", \"#2ca02c\", \"#ff7f0e\"]\n",
        "markers = [\"o\", \"s\", \"^\"]\n",
        "\n",
        "for method, color, marker in zip([\"sigmoid\", \"isotonic\", \"sba\"], colors, markers):\n",
        "    method_data = results_df[results_df[\"calibration_method\"] == method]\n",
        "    plt.scatter(\n",
        "        method_data[\"sm_ece\"],\n",
        "        method_data[\"accuracy\"],\n",
        "        label=method,\n",
        "        alpha=0.7,\n",
        "        c=color,\n",
        "        marker=marker,\n",
        "        s=100\n",
        "    )\n",
        "\n",
        "    z = np.polyfit(method_data[\"sm_ece\"], method_data[\"accuracy\"], 1)\n",
        "    p = np.poly1d(z)\n",
        "    plt.plot(\n",
        "        method_data[\"sm_ece\"],\n",
        "        p(method_data[\"sm_ece\"]),\n",
        "        c=color,\n",
        "        linestyle=\"--\",\n",
        "        alpha=0.5\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"smECE\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs smECE by Calibration Method\")\n",
        "plt.legend(title=\"Calibration Method\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Add correlation information as text\n",
        "correlations = []\n",
        "for method in [\"sigmoid\", \"isotonic\", \"sba\"]:\n",
        "    method_data = results_df[results_df[\"calibration_method\"] == method]\n",
        "    corr = method_data[\"accuracy\"].corr(method_data[\"sm_ece\"]).round(3)\n",
        "    correlations.append(f\"{method}: r = {corr}\")\n",
        "\n",
        "plt.text(\n",
        "    0.02,\n",
        "    0.02,\n",
        "    \"Correlations:\\n\" + \"\\n\".join(correlations),\n",
        "    transform=plt.gca().transAxes,\n",
        "    bbox=dict(facecolor=\"white\", alpha=0.8)\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtwheK9F-Esy"
      },
      "outputs": [],
      "source": [
        "! zip -r results results"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wkNevT4nmkVm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNtvLDIUzXvniYzV29D+G9R"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}